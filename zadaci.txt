STABLO

# DRVO ODLUCIVANJA JE TIP ALGORITMA KOJI RADI SA SVIM VARIJABLAMA !

# prvo moramo da ucitamo dataset nakon sto ga stavimo u root folder
data <- read.csv("travel-times.csv", stringsAsFactors = FALSE)

# gledamo strukturu dataseta
str(data)
summary(data)

# prima dataset, MARGIN = 2 znaci da se izvrsava nad kolonama i FUN je koja funkcija
apply(data, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))

# nijedna varijabla nema NA vrednosti
# varijable FuelEconomy, GoingTo i Comments imaju prazne stringove 
# i varijablama FuelEco i GoingTo cemo te stringove zameniti NA vrednostima
# varijablu Comments, zbog prevelikog broja nedostajucih 
# vrednosti treba ukloniti jer je irelevantna za nas model
# ostace privremeno radi potrebe za neki od narednih koraka

str(data)

# uklanjanje nedostajucih vrednosti
# proveravamo koje od karakter tipova podataka mozemo da pretvorimo
# u factor (kategoricke) varijable
table(data$GoingTo)
table(data$DayOfWeek)
table(data$FuelEconomy)

# vidimo da GoingTo ima samo dve kategorije: Work i Home
# DayOfWeek ima 5 za sve radne dane u nedelji
# FuelEconomy je character varijabla, ali treba je pretvoriti u 
# numericku

# mozemo i length unique da koristimo da bismo videli koliko
# razlicitih vrednosti ima neka varijabla i sve one character varijable
# koje imaju previse razlicitih vrednosti necemo pretvarati u faktor
length(unique(data$GoingTo))   # moze faktor
length(unique(data$DayOfWeek)) # moze faktor
length(unique(data$Date))      # ne moze faktor (uklanjamo kasnije)
length(unique(data$StartTime)) # ne moze faktor (uklanjamo kasnije)

# ovako mozemo da vidimo koliko su procentualno zastupljenje vrednosti
# ako nam nekad bude bilo potrebno: 
# prop.table(table(data$GoingTo))

# kao sto vidimo:

# GoingTo ima samo 2 vrednosti:  Home i Work, svaku "" ili "-" vrednost
# u GoingTo koloni cemo svaku nedostajucu vrednost pretvoriti u onu koja je vise zastupljena. 
# Home ima 97, a Work 103 vrednosti
# tako da cemo sve nedostajuce vrednosti pretvoriti u Work

data$GoingTo[data$GoingTo == ""] <- "Work"
data$GoingTo <- as.factor(data$GoingTo)

# DayOfWeek ima 5 vrednosti, uvek kada imamo mali broj vrednosti
# tu varijablu mozemo da pretvorimo u factor varijablu 
# (ovde nemamo nikakvu NA vrednost, pa direktno pretvaramo u factor)

# data$DayOfWeek <- as.factor(data$DayOfWeek)
data$DayOfWeek <- factor(data$DayOfWeek, levels = c("Monday","Tuesday","Wednesday","Thursday","Friday"))
class(data$DayOfWeek)
levels(data$DayOfWeek)

# FuelEconomy nam nije factor varijabla, ima previse razlicitih vrednosti
# i po vrednostima vidimo da nju treba da pretvorimo
# u numericku varijablu

# sad sredjujemo FuelEconomy

data$FuelEconomy[data$FuelEconomy == "" | data$FuelEconomy == "-"] <- NA
sum(is.na(data$FuelEconomy)) # svih 19 smo pretvorili u NA vrednosti

data$FuelEconomy <- as.numeric(data$FuelEconomy)
class(data$FuelEconomy) # proveravamo da li smo pretvorili FuelEconomy u numericku

# radimo shapiro wilk test da vidimo da li varijabla ima ili nema normalnu raspodelu
shapiro.test(data$FuelEconomy)
# nema normalnu raspodelu jer je p-value < 0.05, pa je sve nedostajuce vrednosti menjamo medijanom

medijanaFuelEco <- median(data$FuelEconomy, na.rm = TRUE)
medijanaFuelEco
data$FuelEconomy[is.na(data$FuelEconomy)] <- medijanaFuelEco

# dobili smo medijanu 8.52 i sve NA vrednosti u FuelEconomy smo zamenili njom

#############################
#### OVDE SMO ZAVRSILI SREDJIVANJE PODATAKA
#############################

# kreiramo izlaznu varijablu
data$Take407All <- ifelse(data$Congestion407 < 0.61 
                             & data$Comments == "", yes = "Yes", no = "No")
data$Take407All <- factor(data$Take407All)

# izbacujemo varijable koje smo koristili za formiranje nove izlazne varijable
data$Congestion407 <- NULL
data$Comments <- NULL

# pokazuje prvih 6 vrednosti, tail() pokazuje poslednjih 6
head(data$Take407All)

# koliko ih ima
table(data$Take407All)

# procentualno
prop.table(table(data$Take407All))
# znaci u 83% slucaja ne treba ici autoputem, a u 17% treba
# treba da napravimo model koji ce da predvidi da li idemo autoputem ili ne

str(data)

data$Date <- NULL
data$StartTime <- NULL
# smatrao sam da su nam nepotrebne varijable Date i StartTime
# uvek kada izbacujemo varijable koje smatramo da nisu potrebne za nas model
# navodimo zbog cega, to moze da bude bilo sta sto vam padne na pamet
# npr. datum i pocetak voznje nisu relevantni
# za nas model jer nece uticati na izlaznu varijablu Take407All ni u kakvom smislu

str(data)

# sredili smo sve podatke, sada kreiramo trening i test set

# install.packages('caret')
library(caret)

set.seed(1010)
indexes <- createDataPartition(data$Take407All, p = 0.8, list = FALSE)
train.data <- data[indexes, ] # svi oni koji se nalaze u tih 80%
test.data <- data[-indexes, ] # svi oni koji se NE nalazed u tih 80%, ostalih 20%

# sada kreiramo klasifikaciono stablo

library(rpart)
tree1 <- rpart(Take407All ~ ., 
                data = train.data,
                method = "class")
tree1

# kao sto vidimo, uzeo je samo MovingTime kao najdominantniji prediktor

library(rpart.plot)
rpart.plot(tree1, extra = 104) # extra 104 pokazuje brojke na odredjen nacin

# sledece sto radimo je pravimo predikciju
tree1.pred <- predict(tree1, newdata = test.data, type = "class")

# sada pravimo matricu konfuzije

# na glavnoj dijagonali matrice konfuzije nam se nalazi broj tacnih
# predikcija, a na sporednoj broj pogresnih predikcija 
tree1.cm <- table(true = test.data$Take407All, predicted = tree1.pred)
tree1.cm

# vidimo da ce nam metrike biti dobra, a da 
# je precision fantastican, 100% smo pozitivnih klasa 
# smo predvideli da su pozitivne


# Dobili smo matricu konfuzije
# TP (True Positive), TN (True Negative), FP (False Positive), FN (False Negative)
# Nama je u zadatku dato da je YES pozitivna klasa
# U prvoj zagradi pise kako su rasporedjeni TP, TN, FP, FN kada je NO pozitivna
# A u drugoj kako su rasporedjeni kada je YES pozitivna klasa
#         predicted
#         NO           YES
# true
# NO      34 (TP) (TN)   0 (FN) (FP)
# YES     2  (FP) (FN)   5 (TN) (TP)

# napisemo funkciju za evaluaciju i odradimo je na cm
# OVO TAKODJE SAMI UCITE DA PISETE! 
# ISPOD JE PRIMER KAD JE YES POZITIVNA KLASA
# KAD JE NO ONDA OBRNEMO INDEKSE, STAVIO SAM ISPOD
getEvaluationMetrics <- function(cm) {
  # levo je kad je YES pozitivna
  # desno je kad je NO pozitivna
  TP <- cm[2,2] # cm[1,1]
  TN <- cm[1,1] # cm[2,2]
  FP <- cm[1,2] # cm[2,1]
  FN <- cm[2,1] # cm[1,2]
  
  accuracy <- sum(diag(cm)) / sum(cm) # tacno predvidjene / sve
  precision <- TP / (TP + FP)      # tacno predvidjenje pozitivne / sve predvidjene pozitivne (prva kolona ili druga u zavisnosti od pozitivne klase)
  recall <- TP / (TP + FN)         # tacno predvidjenje pozitivne / prvi ili drugi red u zavisnosti od pozitivne klase
  F1 <- (2 * precision * recall) / (precision + recall)
  
  c(Accuracy = accuracy, 
    Precision = precision, 
    Recall = recall, 
    F1 = F1)
  
}

eval.tree1 <- getEvaluationMetrics(tree1.cm) 
eval.tree1
# accuracy = procenat tacnih predikcija, ovde smo od ukupnog broja observacija
# u test setu, sto je 41, tacno predvideli 39, pa nam je tacnost visoka

# precision = udeo onih koje smo predvideli da su pozitivne koje su stvarno pozitivne
# ovde smo sve stvarno pozitivne predvideli da su pozitivne, odnosno nijednom
# nismo pogresili da treba da se ide autoputem, a da zapravo ne treba

# recall = udeo observacija koje su stvarno pozitivne koje smo predvideli da su pozitivne
# ovde od ukupno 7 pozitivnih smo predvideli da ih ima 5, tako da smo pogodili 5/7
# za 5 smo rekli da se ide autoputem od ukupno 7 gde treba
# zato nam je recall 0.7142857

# F1 = sluzi za evaluaciju modela kada su precision i recall u balansu, 
# govori koliko je dobar model, u nasem slucaju je 0.833, pa mozemo da 
# zakljucimo da jeste dobar

##################################
##################################

# poslednji deo cross validacija: kucaj <folds> u cheatsheetu
library(e1071)
library(caret)

# radimo 10-fold crossvalidation
numFolds <- trainControl(method = "cv", number = 10) 

# gledamo koja je cp vrednost se pokazala najbolje za nas model
cpGrid <- expand.grid(.cp = seq(from = 0.001, to = 0.05, by = 0.001)) 

set.seed(1010)
crossvalidation <- train(x = train.data[,-10],
                         y = train.data$Take407All,
                         method = "rpart", 
                         trControl = numFolds, # numFolds sto smo dobili iznad
                         tuneGrid = cpGrid) # cpGrid sto smo dobili iznad

crossvalidation

# dobili smo da je najbolji cp = 0.05, to cemo iskoristiti za nase novo drvo
# pa uporediti vrednosti
plot(crossvalidation)

# direktno uzimamo cp iz krosvalidacije
cpValue <- crossvalidation$bestTune$cp

# prune nam smanjuje nase drvo i pravi jednostavniji model
# poenta je da napravimo sto jednostavnije drvo sa sto
# boljim evaluacionim metrikama
# prune prima kao parametre staro drvo i novi cp
# a cp koji smo dobili krosvalidacijom je 0.05
# posle toga samo  napravimo novu predikciju za nase novo stablo
# napravimo novu matricu konfuzije, izracunamo metrike
# i uporedjujemo sa vrednostima prethodnog ili prethodnih stabala
# u ovom slucaju necemo raditi prune, jer je nase drvo vec najjednostavnije
# moguce, zato cemo napraviti novo samo sa drugom vrednoscu complexity parametra
# tree2 <- prune(tree1, cp = cpValue)
tree2 <- rpart(Take407All ~ ., 
               data = train.data,
               method = "class", 
               control = rpart.control(cp = cpValue))

# pravimo predickije
tree2.pred <- predict(tree2, newdata = test.data, type = "class")

# pravimo konfuzionu matricu za drugi model
tree2.cm <- table(true = test.data$Take407All, predicted = tree2.pred) # OVO NEMA U CHEATSHEETU
tree2.cm

# dobili smo isto, tako da ce nam vrednosti metrika biti totalno iste

eval.tree2 <- getEvaluationMetrics(tree2.cm)

eval.tree1
eval.tree2

# sa sledecom linijom koda ispisujemo i uporedjujemo vrednosti na lep nacin
data.frame(rbind(eval.tree1, eval.tree2), row.names = c("prvi","drugi"))

# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji


-----------------------------------------------------------------------------------------------------

KNN




##################################################################
# RADIO SAM BEZ DAYOFWEEK
# ZA DOMACI UBACITE I DAYOFWEEK I VIDITE KAKO SE PROMENIO NAS MODEL
# NA KRAJU BI TREBALO OVO DA DOBIJETE AKO STE LEPO ODRADILI SA ISTIM SEEDOM
# Accuracy Precision    Recall        F1 
# 0.6750000 0.7142857 0.6818182 0.6976744
##################################################################

# SVE VARIJABLE ZA KNN MORAJU DA BUDU NUMERICKE, A IZLAZNA VARIJABLA FAKTORSKA !!!
# NAKON SREDJIVANJA DATASETA MORAMO DA STANDARDIZUJEMO NUMERICKE VARIJABLE !
# AKO JE p > 0.05 onda je normalna raspodela, ako je p < 0.05 onda nije !

data <- read.csv("travel-times.csv", stringsAsFactors = F)

str(data)
summary(data)

# sve varijable moraju da budu numericke i
# moramo da ih standardizujemo, odnosno dovedemo u slican 
# opseg vrednosti da bismo izvrsili KNN algoritam
# neke faktorske cemo nekad pretvarati u numericke, a neke cemo totalno izbaciti
# varijable Date, StartTime, DayOfWeek
# nisu numericke, niti su nam potrebne za model
# kao u prethodnom zadatku stabla, tako da cemo ih izbaciti

length(unique(data$Date))
length(unique(data$StartTime))
length(unique(data$DayOfWeek))
length(unique(data$GoingTo))
# vidimo da Date i StartTime imaju previse razlicitih vrednosti
# pa cemo njih 100% izbaciti
# a sto se tice DayOfWeek, to cemo sad izbaciti, a za domaci cete sami ubaciti
# i videti kako se menja vas model
data$Date <- NULL
data$StartTime <- NULL
data$DayOfWeek <- NULL


apply(data, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))

# 2 '-' ima FuelEconomy
# Prazne stringove ima GoingTo, FuelEconomy i Comments. 
# Comments ima previse nedostajucih vrednosti i treba ukloniti kolonu
# ali cemo to uraditi kasnije jer nam treba za izlaznu varijablu

# opet radimo isto kao prosli put za GoingTo
# NA vrednosti pretvaramo u Work jer njega ima vise
# ali ovaj put moramo faktor da pretvorimo u numeric
# jer nam je to potrebno za izvrsavanje KNN algoritma
data$GoingTo[data$GoingTo == ""] <- NA
table(data$GoingTo)
data$GoingTo[is.na(data$GoingTo)] <- "Work"
data$GoingTo <- as.numeric(as.factor(data$GoingTo))

# pretvaramo nedostajuce vrednosti za FuelEconomy u NA i, posto je to character
# varijabla trenutno, moramo da je pretvorimo u numericku zbog KNN algoritma
# mozemo i samo da kazemo as.numeric(data$FuelEconomy) i on ce sam da pretvori
# sve vrednosti u NA
data$FuelEconomy[data$FuelEconomy == "" | data$FuelEconomy == "-"] <- NA
class(data$FuelEconomy)
data$FuelEconomy <- as.numeric(data$FuelEconomy)

# proveravamo kakvu raspodelu ima FuelEconomy da bismo videli s kojom
# vrednoscu da zamenimo NA vrednosti
shapiro.test(data$FuelEconomy)
# nema normlanu raspodelu, pa NA menjamo medijanom

medijanaFuelEco <- median(data$FuelEconomy, na.rm = TRUE)
data$FuelEconomy[is.na(data$FuelEconomy)] <- medijanaFuelEco

str(data)
# u zadatku nam kaze da pravimo novu varijablu Take407All koja uzima
# vrednost YES ako je vrednost Congestion407 manja od vrednosti na 
# 60-tom percentilu, a NO ako je veca
# ako koristimo funkciju summary(data), 
# dobicemo min, max, 1. kvartil, medijanu, sredinu, 3. kvartil
# ali ne znamo koji je 60ti percentil, za to koristimo funkciju
# quantile koje ima u CHEATSHEETu
percentil60 <- quantile(data$Congestion407, 0.6)
percentil60
data$Take407All <- ifelse(data$Congestion407 < percentil60 
                          & data$Comments == "", yes = "Yes", no = "No")
# sad mozemo da izbacimo Congestion407 i Comments jer smo ih iskoristili
# za kreiranje izlazne varijable i nisu nam vise potrebne
data$Congestion407 <- NULL
data$Comments <- NULL
str(data)
# Take407 je character varijabla, pretvaramo je u factor, s njom ne radimo
# ona je izlazna, prediktor varijable moraju da budu numericke
data$Take407All <- as.factor(data$Take407All)

# sada su nam sve varijable numericke, jedino sto nam preostaje
# je da ih standardizujemo, dovedemo u slican opseg vrednosti kako
# bismo izvrsili nas KNN algoritam

########################################
########################################
# Pre nego sto krenemo sa autlajerima, prvo da vidite sta je to
# i kako smo dosli do toga, za primer cu uzeti jednu varijablu:
# boxplot(data$MaxSpeed) - crta grafik sa 5 tacaka: min, 1. kvartil, medijana, 3. kvartil, max
# boxplot.stats(data$MaxSpeed) - prikazuje statistiku varijable, dobili smo:


# $stats      - ovo je upravo ovih 5 tacaka iznad, respektivno
# [1] 119.0 124.9 127.4 129.8 137.1

# $n          - ovo je broj observacija
# [1] 205
#
# $conf       - confidence interval, interval poverenja za vrednost medijane
# [1] 126.8593 127.9407

# $out        - ovo su konkretni autlajeri, ima ih 6
# [1] 137.8 112.2 114.4 140.9 138.0 137.7
# length(boxplot.stats(data$MaxSpeed)$out) - vraca koliko autlajera imamo

# Sada kad smo prosli ovu funkciju da razumete sta je, iskoristicemo 
# funkciju apply kako bi je izvrsili na sve kolone i vidimo
# da li ima autlajera
########################################
########################################

# kad izvrsimo sledecu funkciju, pise nam za svaku varijablu
# koliko ima outlajera
apply(X = data[,2:8], 2, FUN = function(x) length(boxplot.stats(x)$out))
# posto ima outlajera onda obavezno moramo da uradimo standardizaciju
# na koji nacin zavisi da li varijabla ima ili nema normalnu raspodelu
apply(X = data[,2:8], 2, FUN = function(x) shapiro.test(x))
# nijedna nema normalnu raspodelu

# sve p vrednosti su manje od 0.05, pa je center = median(x) scale = IQR(x), x nam je ta kolona
# ako je neka veca od 0.05, odnosno ima normalnu raspodelu onda pisemo center = TRUE scale = TRUE
# center = TRUE znaci da uzima MEAN, a scale = TRUE da deli sa standardnom devijacijom
# IQR = Interquartile range vam je razlika izmedju 3. i 1. kvartila 
# naravno izbacite kolone koje ne trebaju u odredjenoj funkciji
# data.std je u pocetku matrica, zato mi moramo da ga pretvorimo u dataframe
# da bismo nad njim testirali algoritam
data.std <- apply(X = data[,2:8], 2, FUN = function(x) scale(x, center = median(x), scale = IQR(x)))
data.std <- as.data.frame(data.std)
# sad dodamo Take407All jer je ona ta poslednja, factor varijabla
data.std$Take407All <- as.factor(data$Take407All)
# ako zelimo da specificiramo kojim redosledom idu leveli
# onda mozemo da koristimo factor umesto as.factor, npr.
# factor(data$Take407All, levels = ("No", "Yes"))
# onda ce ici prvo No, pa onda Yes, a sa as.factor sam bira

# dodamo faktorsku kao integer, nije potrebno da je skaliramo jer je binarna
data.std$GoingTo <- as.integer(data$GoingTo)
# promenimo redosled da nam poslednja bude izlazna
data.std <- data.std[,c(9,1:8)]

# ?scale
# PRIMER KAD IMA I NEKIH SA NORMALNOM RASPODELOM, SAMO DODAMO KOLONE NA SLEDECI NACIN:
# data.std$Kolona <- as.vector(scale(data$Kolona, center = TRUE, scale = TRUE)) | scale(x, center = mean(x), scale = sd(x))
# as.vector jer nam inicijalno vraca matricu, a mi ne zelimo matricu u koloni

str(data.std)
summary(data.std)

# sada, kao sto vidite u data.std dataframe-u, imamo standardizovane
# vrednosti i mozemo da idemo dalje



# kad smo zavrsili sa standardizacijom, pravimo train i test setove
library(caret)
set.seed(1010)
indexes <- createDataPartition(data.std$Take407All, p = 0.8, list = FALSE)
train.data <- data.std[indexes, ]
test.data <- data.std[-indexes, ]

# krosvalidacija za 10 iteracija
# nacin za pronalazenje sto boljih vrednosti za parametar
# koji nam je potreban
# za krosvalidaciju uvek e1071 !!!
library(e1071)
library(caret)
numFolds <- trainControl(method = "cv", number = 10) 
# za sledecu funkciju smo izabrali neparne brojeve od 3 do 25
# jer nam je K koliko najblizih vrednosti gledamo
# i mora da bude neparan da bi jedna klasa bila dominantnija
# u odnosu na drugu
kGrid = expand.grid(.k = seq(from = 3, to = 25, by = 2))
# OBAVEZNO SET.SEED !!!
# funkcija ispod je kao rpart kod klasifikacionih stabala
# samo za method pisemo knn, za trControl numFolds koji smo dobili iznad
# i za tuneGrid kGrid koji smo dobili iznad

set.seed(1010)

# KUCAS "train(" U CHEATSHEETU
knn.cv <- train(x = train.data[,-9],
                y = train.data$Take407All,
                method = "knn",
                trControl = numFolds,
                tuneGrid = kGrid)

knn.cv
plot(knn.cv)
# dobili smo da je najbolji value za k = 19, to mozemo uzeti linjom koda ispod

best_k <- knn.cv$bestTune$k

# KUCAS KNN U CHEATSHEETU
library(class)
knn.pred <- knn(train = train.data[,-9], # training data without the output (class) variable
                test = test.data[,-9], # test data without the output (class) variable
                cl = train.data$Take407All, # output (class) variable is specified here
                k = best_k)

# Yes nam je pozitivna klasa
getEvaluationMetrics <- function(cm){
  
  TP <- cm[2,2]
  TN <- cm[1,1]
  FP <- cm[1,2]
  FN <- cm[2,1]
  
  accuracy <- sum(diag(cm)) / sum(cm)
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- (2*precision*recall) / (precision + recall)
  
  c(Accuracy = accuracy, 
    Precision = precision, 
    Recall = recall, 
    F1 = F1)
  
}

knn.cm <- table(true = test.data$Take407All, predicted = knn.pred)
knn.cm
# vidimo da ce nam model imati slabije metrike
# jer je tacno predvideo samo 26/40 observacija
# vidimo da nam su nam vrednosti na sporednoj dijagonali iste
# tako da zakljucujemo da ce nam precision, recall i F1 statistika
# biti iste vrednosti

knn.eval <- getEvaluationMetrics(knn.cm)
knn.eval

# accuracy = procenat tacnih predikcija, ovde smo od ukupnog broja observacija
# u test setu, sto je 40, tacno predvideli 26, pa nam je tacnost niza, odnosno 0.65

# precision = udeo onih koje smo predvideli da su pozitivne koje su stvarno pozitivne
# ovde smo od 22 koje smo rekli da su pozitivne, pogodili 15, odnosno da treba ici autoputem,
# a za 7 smo rekli da treba, a zapravo ne treba, pa nam je precision 0.681

# recall = udeo observacija koje su stvarno pozitivne koje smo predvideli da su pozitivne
# ista nam je vrednost kao za precision jer su iste vrednosti za FP i FN
# dakle od 22 observacije gde treba ici autoputem, rekli smo da treba ici za 15 sto je tacno,
# a za 7 smo rekli da ne treba, a u stvari treba

# F1 = sluzi za evaluaciju modela kada su precision i recall u balansu, 
# govori koliko je dobar model, ovde nam je vrednost F1 statistike 0.681,
# isto kao precision i recall jer su oni potpuno jednaki

# ZA DOMACI UBACITE I DAYOFWEEK I VIDITE KAKO SE PROMENIO NAS MODEL
# NA KRAJU BI TREBALO OVO DA DOBIJETE AKO STE LEPO ODRADILI SA ISTIM SEEDOM
# Accuracy Precision    Recall        F1 
# 0.6750000 0.7142857 0.6818182 0.6976744 



----------------------------------------------------------------------------------------------------


K - means klasterovanje





# RADI SAMO SA NUMERICKIM PODACIMA !

dataSet <- read.csv("world-happiness-report-2016.csv", stringsAsFactors = F)
str(dataSet)
summary(dataSet)

# koristicemo sve varijable osim Country i Region jer k-means klasterovanje 
# radi samo sa numerickim varijablama

all(complete.cases(dataSet)) 
# vraca TRUE ako nijedna nema NA vrednosti, a FALSE ako barem 1 ima neku NA vrednost
which(complete.cases(dataSet) == F)
# vraca koji redovi imaju NA vrednosti, ovde kaze da NA vrednost ima
# red 93, to cemo srediti kasnije

length(unique(dataSet$Region))
length(unique(dataSet$Country))

apply(dataSet, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(dataSet, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(dataSet, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(dataSet, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))
# Region ima prazan string, ali njega necemo koristiti u modelu, pa ga necemo sredjivati
# Freedom ima NA vrednost, pa cemo je zameniti medijanom ili meanom

# gledamo za Freedom
shapiro.test(dataSet$Freedom)
# nema normalnu raspodelu, menjamo medijanom
medianFreedom <- median(dataSet$Freedom, na.rm = T)
dataSet$Freedom[is.na(dataSet$Freedom)] <- medianFreedom


# proveravamo outliere
apply(dataSet[,3:13], 2, FUN = function(x) length(boxplot.stats(x)$out))
# Government.Trust i Dystopia.Residual imaju 12 i 6 outliera

boxplot(dataSet$Government.Trust, xlab = 'Goverment.Trust')
boxplot(dataSet$Dystopia.Residual, xlab = 'Dystopia.Residual')
# Goverment.Trust ima samo outliere sa ekstremno visokim vrednostima
# Dystopia ima 1 outlier sa ekstremno visokom vrednoscu, ostale sa ekstremno niskim vrednostima

# koristimo funckiju Winsorize iz paketa DescTools (nema u cheatsheetu)
# kako bismo transformisali model i izbacili outliere
# za velike vrednosti cemo koristiti 95ti percentil, a za male 5ti percentil
# ovo nam je defaultno, ali ako ne budemo ovime izbacili sve outliere
# onda moramo da promenimo percentile

# install.packages('DescTools')
library(DescTools)
# ovde smo za donji percentil stavili 0 jer nemamo niske vrednosti
# ali visoke cemo zameniti 95tim percentilom inicijalno
# posle provere da li su nestali outlieri, videcemo da nisu
# pa cemo pokusati opet sa 94. percentilom i na kraju
# ce se nestati tek kad budemo iskoristili 92.5 percentil
Goverment.Trust_w <- Winsorize(dataSet$Government.Trust, probs = c(0, 0.925))
dataSet$Government.Trust <- Goverment.Trust_w
# proveravamo da li smo izbacili outliere
boxplot(dataSet$Government.Trust, xlab = 'Goverment.Trust') 
# jesmo

# Dystopia.Residual ima i preniske i previsoke vrednosti, pa cemo koristiti
# i donji i gornji percentil ovaj put
Dystopia.Residual_w <- Winsorize(dataSet$Dystopia.Residual, probs = c(0.05, 0.95))
dataSet$Dystopia.Residual <- Dystopia.Residual_w
boxplot(dataSet$Dystopia.Residual, xlab = 'Dystopia.Residual')
# izbacili smo i ovde

# zavrseno sredjivanje outliera



# normalizacija i model i elbow
# normalizaciju mozemo da radimo jer smo izbacili outliere

normalize_var <- function( x ) {
  if ( sum(x, na.rm = T) == 0 ) x
  else ( (x - min(x, na.rm = T)) / (max(x, na.rm = T) - min(x, na.rm = T)) )
}

# normalizujemo numericke kolone
data.norm <- as.data.frame(apply(dataSet[,3:13], 2, normalize_var))
summary(data.norm)

# nase varijable ne smeju da budu visoko korelisane jer ce to uticati
# negativno na nas model, tako da proveravamo multikolinearnost
data_cor <- cor(data.norm)

library(corrplot)
corrplot.mixed(data_cor)
# vidimo da su nam Happiness.Rank, Happiness.Score, 
# Lower.Confidence.Interval, Upper.Confidence.Interval,
# Economy, Family, Life.Expectancy, Freedom i Dystopia.Residual 
# visoko korelisani, pa cemo izbacivati jednu po jednu i videti sta se desava

data.norm$Happiness.Rank <- NULL
data.norm$Happiness.Score <- NULL
data.norm$Lower.Confidence.Interval <- NULL
data.norm$Upper.Confidence.Interval <- NULL
# data.norm$Economy <- NULL

data_cor <- cor(data.norm)
corrplot.mixed(data_cor)


# pravimo eval.metrics i k 2:8
eval.metrics <- data.frame()

# kmeans u cheatsheetu, direktno je ugradjena funkcija u R, ne vadimo iz paketa
# moramo da navedemo koji numericki dataframe koristi, koliko klastera pravi,
# max iteracija (da ne bi isao u nedogled) i koliko puta pozivamo algoritam
# jer inicijalno moze da nam da losije pozicije klastera, pa moramo da ga izvrsimo
# vise puta da bismo nasli sto bolje
for(k in 2:8){
  
  set.seed(1010) # jer nasumicno biramo klastere
  km <- kmeans(data.norm, centers = k, iter.max = 20, nstart = 1000)
  
  eval.metrics <- rbind(eval.metrics, c(k, km$tot.withinss, km$betweenss/km$totss))
  # na postojeci sadrzaj dataframea, dodaj tot.withinss i ratio betweenss / totss
  # withinss => suma kvadrata odstupanja observacija od centra njihovog klastera
  # tot.withinss => suma withinss svih klastera
  # between_SS => suma kvadrata odstupanja centara klastera od globalnog centra 
  # total_SS => suma kvadrata odstupanja svake observacije od globalnog centra
  
}

# dajemo nazive kolonama
colnames(eval.metrics) <- c("clusters", "tot.withinss", "ratio")
eval.metrics

# crtamo krivu i gledamo gde je najveci prelom
library(ggplot2)
ggplot(data = eval.metrics, mapping = aes(x = 2:8, y = tot.withinss)) + 
                  geom_line() + 
                  geom_point()
                  

# mozemo da vidimo i tacnu brojku koliko se promenilo
# ako iskoristimo funkciju compute.difference iz Utility.R
source("Utility.R")
diff_df <- apply(eval.metrics[,2:3], 2, compute.difference)
diff_df

# da bismo imali kolonu za k da znamo na sta se odnose ove vrednosti
diff_df <- cbind(k = 2:8, diff_df)
diff_df

# u prvoj koloni smo dobili NA jer radimo razliku izmedju dve susedne vrednosti
# 2. kolona predstavlja smanjenje tot.withinss kad je k+1
# 3. kolona je povecanje racia za k+1

# po ovom diff_df vidimo da je 3 najbolji broj klastera
# jer ima najvecu razliku u odnosu na prethodni i za tot.withinss i za ratio

sample.3k <- kmeans(x = data.norm, centers = 3, iter.max = 20, nstart = 1000)
sample.3k
# ovo pokazuje:

# 3 klastera od 79, 49, 29 observacija

# srednje vrednosti klastera po varijablama

# clustering vector: koja observacija pripada kom klasteru
# suma kvadrata odstupanja observacija od centra klastera (za svaki pise pojedinacno), 
# sto manja to bolja jer je bliza centru klastera naravno
# vidimo da 2. klaster najvise odstupa, sto je i logicno jer on ima
# najvise observacija

# withinss => suma kvadrata odstupanja observacija od centra njihovog klastera
# between_SS => suma kvadrata odstupanja centara klastera od globalnog centra 
# total_SS => suma kvadrata odstupanja svake observacije od globalnog centra
# sto je ratio veci, to je bolji, u nasem slucaju je 43.2%
# ako je veci ne znaci da cemo moci da interpretiramo rezultate
# najbitnije je da krajnji rezultati budu razumljivi

# pozivamo summary.stats iz Utility.R 
# prvi parametar je dataset, drugi raspored po klasterima, a treci je broj klastera
sum.stats <- summary.stats(data.norm, sample.3k$cluster, 3)
sum.stats

# mean pokazuje srednju vrednost, a SD nam je standardna devijacija,
# odnosno odstupanje (disperzije) od centra
# freq je broj zemalja, u prvom klasteru je 79, u drugom 49, broj u trecem je 29 zemalja,

# imamo mali disbalans sto se tice klastera u pitanju njihove velicine

# trazimo ono sto je specificno za svaki od ovih klastera

# disperzije od centra su nam svuda slicne

# primecujemo da treci klaster ima najvece vrednosti za sve osim za residual distopije
# pa mozemo da zakljucimo da su sve varijable koje smo koristili korelisane
# pa mozemo da kazemo da su zemlje u trecem klasteru bogatije, viseg statusa

# drugi klaster ima malu vrednost za poverenje u vladu,
# ali odstupa i u prosecnom broju clanova porodice, ocekivanom zivotnom veku
# i BDP po glavi stanovnika jer su nizi u odnosu na druga dva klastera
# pa mozemo reci da su zemlje u drugom klasteru siromasnije, nizeg statusa

# vidimo da prvi klaster ima veoma malo poverenja u vladu, tu odstupa
# a ostali rezultati su izmedju druga dva klastera, pa se moze
# reci da su ove drzave srednjeg statusa

# ovo je primer komentarisanja ovakvih rezultata, interpretirajte ih kako god
# zelite samo da bude smisleno








----------------------------------------------------------------------------------------------------


LINEARNA REGRESIJA



# RADI SAMO SA NUMERICKIM PODACIMA!
# IZLAZNA VARIJABLA JE NUMERICKA!

# da je pisalo da treba da se ucita iz ISLR paketa onda treba
# install.packages('ISLR')
# library(ISLR)
# str(imeDataSeta)
# dataSet <- imeDataSeta

data <- read.csv("Video_Games_Sales_2017_reduced.csv", stringsAsFactors = F)

tempSub <- subset(data, (data$Platform == "PS2" 
                         | data$Platform == "PS3" | data$Platform == "PS4"))

rm(data)

str(tempSub)

# prvo sredjujemo izlaznu varijablu, moramo da obrisemo sve nedostajuce vrednosti
# jer moramo da izvrsimo predvidjanje nad postojecim podacima!
sum(is.na(tempSub$User_Score))
sum(tempSub$User_Score == "", na.rm = T)
sum(tempSub$User_Score == "-", na.rm = T)
sum(tempSub$User_Score == " ", na.rm = T)
table(tempSub$User_Score)

# vidimo da imamo prazne stringove i 'tbd' tako da cemo to pretvoriti u NA vrednosti
# i izbaciti iz naseg dataseta koji koristimo za model!
tempSub$User_Score[tempSub$User_Score == "" | tempSub$User_Score == "tbd"] <- NA

# vraca samo redove koje nemaju NA vrednosti za 13. kolonu, odnosno nasu
# izlaznu varijablu User_Score
dataSub <- tempSub[complete.cases(tempSub[,13]), ]

rm(tempSub)

# ubacili su N/A vrednosti takodje (za Year_of_Release npr.)
# to sam video zato sto sam izvrsio table(dataSub$Year_of_Release)...
# ne znam da li kazu na ispitu
apply(dataSub, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(dataSub, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(dataSub, MARGIN = 2, FUN = function(x) sum(x == "N/A", na.rm = T))
apply(dataSub, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(dataSub, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))
# varijable Critic_Score, Critic_Count imaju po 174 NA vrednosti

# varijable Developer i Rating imaju 2 i 17 praznih stringova respektivno

# Year_of_release ima 25 N/A vrednosti i Publisher 1

length(unique(dataSub$Name))
length(unique(dataSub$Publisher))
length(unique(dataSub$Developer))

length(unique(dataSub$Rating))
length(unique(dataSub$Platform))
length(unique(dataSub$Genre))

# varijable Name, Publisher i Developer cemo izostaviti iz 
# daljeg istrazivanja jer imaju previse razlicitih vrednosti
# pa ih ne mozemo transformisati u faktor varijable

dataSub$Name <- NULL
dataSub$Publisher <- NULL
dataSub$Developer <- NULL

str(dataSub)

# sredicemo year_of_release jer ima N/A vrednosti
# sredicemo critic_score i critic_count jer imaju NA vrednosti
# sredicemo rating jer ima prazne stringove

# YEAR OF RELEASE IMA N/A VREDNOSTI
# i trenutno je character varijabla, pa cemo je pretvoriti u factor, pa u numeric
# isto tako cemo uraditi za User_Score koji ima prazne stringove

# Year_of_release necemo transformisati direktno u numericku, vec prvo u faktorsku
# jer imati nivo za svaku godinu, pa tek onda u numericku
sort(table(dataSub$Year_of_Release))
dataSub$Year_of_Release[dataSub$Year_of_Release == "N/A"] <- "2004"
dataSub$Year_of_Release <- as.numeric(as.factor(dataSub$Year_of_Release))

# rating
sort(table(dataSub$Rating))
dataSub$Rating[dataSub$Rating == ""] <- "T"
dataSub$Rating <- as.numeric(as.factor(dataSub$Rating))

# genre
dataSub$Genre <- as.numeric(as.factor(dataSub$Genre))


# platform
dataSub$Platform <- as.numeric(as.factor(dataSub$Platform))

# mozete da stavite i redni broj kolone umesto nazive varijabli u sledecoj liniji
apply(dataSub[,c("Critic_Score", "Critic_Count")], 2, FUN = function(x) shapiro.test(x))
# nedostajuce vrednosti numerickih varijabli menjamo srednjom vrednoscu
# ako imaju normalnu raspodelu, a medijanom ako nemaju
# nijedna nema normalnu raspodelu, pa ih menjamo njihovom medijanom

medianCriticScore <- median(dataSub$Critic_Score, na.rm = T)
medianCriticCount <- median(dataSub$Critic_Count, na.rm = T)

dataSub$Critic_Score[is.na(dataSub$Critic_Score)] <- medianCriticScore
dataSub$Critic_Count[is.na(dataSub$Critic_Count)] <- medianCriticCount

dataSub$User_Score <- as.numeric(dataSub$User_Score)

str(dataSub)

# sad su nam sve varijable numericke i izbacili smo nepotrebne
# zavrseno sredjivanje

# sad gledamo korelacije
library(corrplot)
matrica <- cor(dataSub)
matrica[,11] # izabrali smo 11. kolonu/varijablu User_Score
corrplot(matrica, method = "number", type = "upper", diag = FALSE)
# jedini koeficijent korelacije koji se moze smatrati od znacaja
# u odnosu na User_Score je Critic_Score = 0.49,
# ostale su sve slabo korelisane
# (nema pravila koji stepen korelacije birate, uvek gledate relativno 
# u odnosu zadatak, mogu i da vam kazu npr. da gledate stepen korelacije
# koji je veci od 0.6)
# ovde vidimo da je jedino relevantno Critic_Score,
# ostali stepeni korelacije su niski
# takodje, kad izaberemo varijable koje su nam relevantne
# moramo da izbegnemo ulazne varijable (ove koje koristimo kao prediktore)
# koje su medjusobno visoko korelisane, onda cemo samo jednu po jednu izbacivati (videcete kad budemo radili VIF)
# to radimo jer kad su medjusobno visoko korelisane, onda ce uticati na model u losem smislu

# pravimo trening i test setove
library(caret)
set.seed(1010)
indexes <- createDataPartition(dataSub$User_Score, p = 0.8, list = FALSE)
train.data <- dataSub[indexes, ]
test.data <- dataSub[-indexes, ]

# pravimo model
# sad za lm uzimamo samo ove koje imaju jacu korelaciju, 
# u ovom slucaju samo Critic_Score
lm1 <- lm(User_Score ~ Critic_Score, data = train.data)
summary(lm1)
# za svako povecanje Critic_Score povecava nam se User_Score za 0.056 poena
# izgled linearne krive y = 3.246993 + 0.056x
# max zvezdica je 3, sto veci broj zvezdica, to je znacajnija predikcija
# intercept znaci kolika bi vrednost bila da su svi prediktori 0 (nije uvek realno)
# residual predstavlja razliku izmedju stvarnih i predvidjenih vrednosti
# i ovde iznosi 1.264
# r-squared znaci da nas model objasnjava 24.42% varijabilieteta zavisne promenljive User_Score
# f-statistika je 431.6, a p-value < 0.05, dakle postoji zavisnost izmedju 
# zavisne promenljive i prediktora i ima smisla razmatrati ovaj nas model

# sad proveravamo multikolinearnost, kolonearnost izmedju prediktora
# ne smemo da uzmemo 2 varijable koje imaju visoku kolinearnost
# OVO RADI AKO IMA 2 ILI VISE VARIJABLI, OVDE IMA SAMO JEDNA, PA NECE RADITI
# install.packages("car")
library(car)
vif(lm1) # variance inflation factor
# ovde imamo samo jednu varijablu, Critic_Score, pa nece raditi !


##############################################
##############################################
# OVAJ MODEL BEZ LIMITA, MOZETE DA 
# GA URADITE DA BISTE VIDELI DA LI JOS NESTO DA UBACITE U MODEL
# ODNOSNO DA LI MOZETE DA NAPRAVITE BOLJI MODEL

# sad pravimo novi model bez limita
lm2 <-  lm(User_Score ~ ., data = train.data)
summary(lm2)
# varijable koje se mogu smatrati od znacaja su 
# YearOfRelease, Genre, Critic_Score, Critic_Count i Rating
# residual predstavlja razliku izmedju predvidjenih i stvarnih vrednosti
# i ovde iznosi 1.132
# r-squared, nas model opisuje 39.85% varijabilieteta zavisne promenljive
# povecao nam se, sto je logicno, povecava se sto vise prediktora imamo u modelu
# f-statistika je 73.15, a p-value < 0.05, dakle postoji zavisnost izmedju 
# ovih varijabli

# OVDE IMA VISE VARIJABLI PA RADIMO PROVERU MULTIKOLINEARNOSTI
# install.packages("car")
library(car)
vif(lm2)
sqrt(vif(lm2))
sort(sqrt(vif(lm2))) # sortiramo da bude preglednije

# varijable koje imaju sqrt(vif(lm)) veci od 2 su problematicne
# postoji velika kolinearnost izmedju varijabli JP_Sales, Other_Sales, EU_Sales, 
# NA_Sales i Global_Sales
# izbacujemo jednu po jednu, pa gledamo kako se nas model menja

# ova linija koda nam pokazuje koeficijente za nase prediktore
coef(lm2)

# sve osim Global_Sales
lm3 <- lm(User_Score ~ . - (Global_Sales),
           data = train.data)
summary(lm3)

# eto, izbacivanjem Global_Sales je ostao isti R-squared i isti residual  std. error

sort(sqrt(vif(lm3)))
# ostalo nam je samo da izbacimo Platform jer ima visoku korelaciju sa year_of_release

# takodje, mozemo da izbacimo varijable koje se ne smatraju znacajnim, ove bez zvezdica
# i sa jednom zvezdicom

lm4 <- lm(User_Score ~ . - (Global_Sales + Platform),
          data = train.data)
summary(lm4)
sort(sqrt(vif(lm4)))
# eto, sad nemamo multikolinearnost
# izbacicemo sve varijable koje nisu znacajne i napraviti konacan model

lm5 <- lm(User_Score ~ Year_of_Release + Genre + EU_Sales + JP_Sales + Critic_Score + Rating,
           data = train.data)
summary(lm5)
sort(sqrt(vif(lm5)))

# vidimo da su nam ovde sve varijable od znacaja
# residual predstavlja razliku izmedju predvidjenih i stvarnih vrednosti
# i ovde iznosi 1.136
# r-squared, nas model opisuje 39.16% varijabilieteta zavisne promenljive
# smanjio nam se jer imamo manje prediktora nego u prethodnom modelu
# f-statistika je 142.8, a p-value < 0.05, dakle postoji zavisnost izmedju 
# ovih varijabli


#####################################################
#####################################################


# pravimo 4 plota
graphics.off()
par(mfrow = c(1,1)) # da imamo samo 1 red i 1 kolonu za grafove
par(mfrow = c(2,2)) # da imamo 2 reda i 2 kolone za grafove
plot(lm5)

# Prva slika govori koliko je prepostavka o linearnosti zadovoljenja, 
# predikcija se moze smatrati merodavnom ako je crvena linija blizu 
# toga da bude ravna, odnosno tackice su blizu toga da budu jednako rasporedjene
# Residuals su reziduali (razlika izmedju stvarnih i predvidjenih vrednosti)
# a fitted values predvidjene vrednosti 
# ovde se tezi da reziduali budu 0, tako da sto je crvena linija
# bliza 0, to je nas model bolji
# u nasem slucaju pretpostavka linearnosti nije zadovoljavajuca

# druga slika govori o tome da li su reziduali normalno rasporedjeni
# U ovom slucaju nisu jer u pocetku odstupaju u odnosu na isprekidanu liniju

# treca slika proverava da li rezidulali imaju jednake 
# varijanse (homoskedasticnost), ukoliko imamo horizontalnu liniju
# bilo gde na plotu, znaci da imaju
# kod nas nije skroz horizontalna, tako da se moze reci da se razlikuju

# cetvrta da li ima observacija sa veoma velikim/malim vrednostima 
# tj. ekstemnim vrednostima, Kukova distanca nam je preko isprekidanih crvenih linija
# ako je neka observacija preko te linije, znaci da imamo ekstremne vrednosti
# ovde nemamo varijable koje su van isprekidane linije
# ako kucate plot(lm3) videcete
# da imamo neke koje su blizu Kukove distance, ali ne preko
# tako da nece praviti problem
# da ih imamo, te vrednosti van Kukove distance ce uticati na model u losem smislu

# nas model ne ispunjava idealne uslove, ali je prihvatljiv

lm5.pred <- predict(lm5, newdata = test.data)
head(lm5.pred)
head(test.data$User_Score)

# mozete da da koristite ovaj ggplot, ali nije neophodno
test.data$User_Score_pred <- lm5.pred

library(ggplot2)
ggplot(test.data) +
    geom_density(aes(x = User_Score, color = 'actual')) +
  geom_density(aes(x = User_Score_pred, color = 'predicted'))

# vidimo da je samo u tacki 7.5 model izuzetno omanuo

# RSS = Residual Sum of Squares
# TSS = Total Sum of Squares
# sve ovo ispod je u cheatsheetu !!!

# residual je razlika izmedju stvarne i predvidjene vrednosti,
# nju sumiramo i kvadriramo da bismo dobili RSS:
RSS <- sum((lm5.pred - test.data$User_Score)^2)

# razlika izmedju vrednosti u testu i srednje vrednosti u trainu,
# nju sumiramo i kvadriramo da bismo dobili TSS
TSS <- sum((mean(train.data$User_Score) - test.data$User_Score)^2)

# ovo je formula za RSQUARED
rsquared <- 1 - RSS / TSS
rsquared
# ukupan objasnjeni varijabilitet je 36.79%


summary(lm5)
# uporedjujemo sa rsquared nad trainom i nad testom i vidimo 
# da je veca na trainu
# ukupan objasnjeni varijabilitet je 36.79%, a na trainu je 39.16%

# RMSE = Root Mean Squared Error, koliku gresku pravimo s predikcijama
# RSS / broj observacija u test setu
RMSE <- sqrt(RSS/nrow(test.data))
RMSE

# pravimo gresku 1.219 poena za izlaznu varijablu User_Score

# OVO NEMA U CHEATSHEETU !
mean(test.data$User_Score) # mean, srednja vrednost nam je 7.3 poena
RMSE/mean(test.data$User_Score)
# greska iznosi 17.07% od srednje vrednosti poena, sto govori da nam je model
# solidan

# NAPOMENA:
# MOZETE DA NAPRAVITE VISE LM - LINEARNIH MODELA I UPOREDJIVATI 
# KOJI JE BOLJI
# POENTA ZADATKA JE KORISCENJE FUNKCIJA, PRAVLJENJE MODELA
# I PISANJE STO VISE KOMENTARA U KONTEKSTU ZADATKA
# DA BI ONI VIDELI DA VI RAZUMETE STA RADITE






----------------------------------------------------------------------------------------------------


NAIVNI BAJES



# RADI SA FAKTOR VARIJABLAMA!
# RADI I SA NUMERICKIM AKO IMAJU NORMALNU RASPODELU, 
# A AKO NEMAJU, MORAJU DA SE DISKRETIZUJU!

# POSTOJE 2 VRSTE DISKRETIZACIJE:
# 1. DISKRETIZACIJA U INTERVALE JEDNAKE DUZINE (intervalna diskretizacija)
# 2. DISKRETIZACIJA U INTERVALE ISTE FREKVENCIJE (kvantilna diskretizacija)
# kvantilna obicno daje bolje rezultate, pa cemo nju ovde koristiti

data <- read.csv("wines.csv", stringsAsFactors = FALSE)
str(data)
# ovaj dataframe sam morao sam da popravim jer nemamo konkretan CSV fajl
# R iz nekog razloga dodaje kolonu X koja oznacava redni broj observacije
# pokusao sam da izbrisem, ali neuspesno
# zbog toga radim sledecu liniju koda, da izbacim to X odmah, pa normalno radimo zadatak
data$X <- NULL

str(data)

dataSub <- subset(data, (country == "France" | country == "Argentina" | country == "Italy"))
summary(dataSub)

apply(dataSub, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(dataSub, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(dataSub, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(dataSub, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))

# Designation ima 1065 praznih stringova, region ima 9
# nijedna varijabla nema '-'
# Price ima 39 NA vrednosti i te redove moramo ukloniti
# jer se od varijable Price kreira izlazna varijabla Price_Category

# izbacujemo sve observacije sa nepoznatom varijablom Price
dataSub <- dataSub[complete.cases(dataSub[,5]),]
# moze i ovako dataSub <- dataSub[!is.na(dataSub$price),]

length(unique(dataSub$designation))
# posto designation ima 1859 razlicitih vrednosti, a ukupan broj observacija
# je 3388 nema poente da je pretvorimo u faktor zato cemo je ukloniti
dataSub$designation <- NULL

length(unique(dataSub$region))
# ima 458 sto je mnogo za faktor varijablu, pa i region takodje brisemo
dataSub$region <- NULL

dataSub$description <- NULL # description nema uticaja na dalje analze jer ne utice na cenu

# Country ima samo 3 razlicite vrednosti, jer smo od toga rekli da nam se sastoji subset
# pa cemo je pretvoriti u faktor
dataSub$country <- factor(dataSub$country)
levels(dataSub$country)

length(unique(dataSub$title))
# Title takodje ima previse razlicitih vrednosti, pa i njega uklanjamo
dataSub$title <- NULL

length(unique(dataSub$province))
# 23 nivoa, mozemo da ostavimo
dataSub$province <- as.factor(dataSub$province)

str(dataSub)

length(unique(dataSub$variety))
# variety takodje ima previse razlicitih vrednosti, pa i njega uklanjamo
dataSub$variety <- NULL

length(unique(dataSub$winery))
# winery takodje ima previse razlicitih vrednosti, pa i njega uklanjamo
dataSub$winery <- NULL

str(dataSub)

str(dataSub)
prviKvartil <- quantile(dataSub$price, 0.25)
prviKvartil
dataSub$price_category <- ifelse(dataSub$price <= prviKvartil, 
                                 yes = "cheap", no = "not_cheap")

# price nam sada vise nije potrebna jer smo napravili izlaznu
# price category
dataSub$price <- NULL
dataSub$price_category <- factor(dataSub$price_category)

str(dataSub)

# zavrsili smo sa sredjivanjem podataka, sada radimo diskretizaciju numerickih varijabli
# ako nemaju normalnu raspodelu,
# pravimo train i test setove i pravimo model

shapiro.test(dataSub$points)
# Nema normalnu raspodelu, pa radimo diskretizaciju !

# vidimo koliko vinarija upada u neki opseg poena
# ovo nije toliko bitno za ispit
library(ggplot2)
ggplot(dataSub, aes(x = points)) + geom_histogram()

dataSub$points <- as.numeric(dataSub$points)
points <- dataSub$points
points.df <- as.data.frame(points)

# pretvorili smo points u numeric data frame 
# jer funckija discretized (ova ispod)
# prima to kao parametar

# install.packages("bnlearn")
library(bnlearn)
discretized <- discretize(data = points.df,
                          method = "quantile",
                          breaks = c(5))
# diskretizujemo sve koje nemaju normalnu raspodelu
# npr. da je bilo vise kolona onda bi bilo
# discretized <- discretize(dataSub[,c(2,3,6,7,9)],
#                           method = "quantile",
#                           breaks = c(5,2,5,2,5)) 
# stavljamo da podeli u 5 intervala sve kolone, to je neki rule of thumb,
# ako javlja gresku onda promenimo broj intervala
# u novijim verzijama Ra ne bi trebalo da javi gresku
# pa sami moramo da vidimo i izmenimo broj intervala da bi bio
# sto pravilniji broj observacija u svakom intervalu
# neka varijabla nekad ima jako nepravilnu raspodelu, odnosno
# jako mali opseg vrednosti da bi napravio 5 intervala
# zato moramo da smanjimo broj intervala

# u ovom konkretnom primeru sam ostavio 5 intervala, jer kad stavimo
# drugi broj onda daje previse drugaciji broj observacija u invervalima

summary(discretized)

newData <- as.data.frame(cbind(discretized, dataSub[,c(1,3,4)]))
# spojimo dataframe sa diskretizovanim varijablama
# sa varijablama iz originalnog dataframea koje imaju normalnu raspodelu ili su faktorske
# u newData

str(newData)

# sad su nam ostale sve faktor varijable i mozemo da nastavimo dalje

# train i test
library(caret)
set.seed(1010)
indexes <- createDataPartition(newData$price_category, p= 0.80, list = F)
train.set <- newData[indexes,]
test.set <- newData[-indexes,]


# install.packages("e1071")
library(e1071)
nb1 <- naiveBayes(price_category ~ ., data = train.set)
nb1
# A-priori probability pokazuje prave verovatnoce
# u 26% slucajeva ce vino biti jeftino, a u 74% slucajeva nece biti jeftino

nb1.pred <- predict(nb1, newdata = test.set, type = "class")
nb1.pred
# ako umesto type = "class" (ovako dobijamo klase kao predikcije)
# stavimo "raw", onda dobijamo konkretne verovatnoce za cheap i not_cheap
# model ce naravno da izabere vecu verovatnocu kao resenje
# mi cemo kasnije podesiti threshold, odnosno
# birati odredjenu klasu samo ako je verovatnoca veca od vrednosti
# koju smo mi zadali

nb1.cm <- table(true = test.set$price_category, predicted = nb1.pred)
nb1.cm

# pozitivna klasa je cheap, receno u zadatku

#                       predicted
#       true       cheap        not_cheap
#       cheap        98        80
#       not_cheap    49       450

getEvaluationMetrics <- function(cm) {
  
  TP <- cm[1,1] # true positive
  TN <- cm[2,2] # true negative
  FP <- cm[2,1] # false positive
  FN <- cm[1,2] # false negative
  
  accuracy <- sum(diag(cm)) / sum(cm)
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- (2 * precision * recall) / (precision + recall)
  
  c(Accuracy = accuracy, 
    Precision = precision, 
    Recall = recall, 
    F1 = F1)
}

nb1.eval <- getEvaluationMetrics(nb1.cm)
nb1.eval

# accuracy = procenat tacnih predikcija, ovde smo od ukupnog broja observacija
# u test setu, sto je 677, tacno predvideli 548, pa nam je tacnost solidna, odnosno 80.9%

# precision = udeo onih koje smo predvideli da su pozitivne koje su stvarno pozitivne
# ovde smo od 147 vina za koja smo rekli da su jeftina
# pogodili 98 da jesu, a za 49 smo rekli da su jeftina
# umesto da nisu, pa nam je precision nesto nizi, odnosno 66.7%

# recall = udeo observacija koje su stvarno pozitivne koje smo predvideli da su pozitivne
# od ukupno 178 vina koja su jeftina smo tacno predvideli 98, a 80 smo pogresili i
# rekli da nisu jeftina, zato nam je i recall 55.05%

# F1 = sluzi za evaluaciju modela kada su precision i recall u balansu, 
# govori koliko je dobar model, ovde nam je vrednost F1 statistike 60.3%,
# sto je lose jer su nam niski i precision i recall, morali bismo da poboljsamo model

# sad trazimo threshold preko ROC krive
# to je optimalna verovatnoca za specificity i sensitivity
# onda se pravi nova predikcija za ROC krivu, ali TYPE = RAW
# da bismo videli tacne verovatnoce za svaku klasu

nb2.pred.prob <- predict(nb1, newdata = test.set, type = "raw")
nb2.pred.prob

# kreiranje ROC krive, kucaj PROC u cheatsheetu


# install.packages("pROC")
library(pROC)
nb2.roc <- roc(response = as.integer(test.set$price_category),
               predictor = nb2.pred.prob[,1],
               levels = c(2,1))
plot.roc(nb2.roc)

# response je izlazna varijabla, ali vrednost treba da bude integer vrednost (NE PISE U CHEATSHEETU !!!!)
# za predictor vrednost dajemo verovatnocu pozitivne klase, odnosno prva kolona
# levels (NE PISE U CHEATSHEETU !!!!!) je uredjen da prvo ide negativna, pa pozitivna klasa
# zato smo mi stavili c(2,1) jer smo prvo zadali poziciju
# negativne klase (not_cheap), pa pozitivnu pozitivne (cheap)

# sensitivity odgovara recallu (TPR - true positive rate)
# u odnosu na sve prodavnice koje imaju jeftino vino (koje su pozitivne),
# koji je udeo onih koje smo mi predvideli da imaju jeftino vino (da jesu pozitivne)

# specificity je isto samo se odnosi na negativnu klasu (FPR - false positive rate)
# u odnosu na sve prodavnice koje imaju skupo vino (koje su negativne),
# koji je udeo onih koje smo mi predvideli da imaju skupo vino (da jesu negativne)

# da je not_cheap pozitivna klasa 
# onda ide predictor = nb2.pred.prob[,2],levels = c(1,2)

nb2.roc$auc
# sto je AUC - area under the curve veca, to se klasifikator smatra boljim
# ako je 1 onda moze perfektno da razlikuje koja je pozitivna, a koja negativna klasa
# a ako je na primer 0.7 onda ima 70% sanse da razlikuje koja je pozitivna, a koja negativna
# a ako je 0.5 onda ne moze da razlikuje, to je najgora situacija
# 0.8374 odnosno 83.74% je u nasem slucaju (znaci da je dobra, sve preko 0.9 se smatraju bas dobrim modelima)
# sada pravimo plot da bismo videli threshold

plot.roc(nb2.roc, print.thres = TRUE, print.thres.best.method = "youden")
# print.thres je TRUE da bi se ispisao najbolji threshold
# youden method bira threshold gde je suma specificity i sensitivity maximalna
# treshold je 0.242, specificity je 0.756, a sensitivity je 0.764

# coords u CHEATSHEET-u, da nadjemo koordinate naseg thresholda
nb2.coords <- coords(nb2.roc, 
                     ret = c("accuracy", "spec", "sens", "thr"), 
                     x = "local maximas")
nb2.coords

# vraca koordinate za nasu nb2.roc 
# ret (return) znaci sta da nam vrati od parametara (ima ih vise, ove 4 su najbitnije)
# local maximas znaci da vrati sve lokalne maximume (tacke na roc krivi)
# transpose uvek stavljamo FALSE zbog prikaza rezultata nb2.coords
# (da ne bude transponovano)

# ovo radimo da bismo izabrali najbolji threshold da maximiziramo
# specificity i sensitivity (ovo se trazi u zadatku, a mogu da vam daju i 
# da nadjete threshold samo za najveci specificity npr.)

# prvi model ima dobar accuracy, ali nizi precision i recall, ako zelimo da povecamo recall
# potrebno je da nadjemo vrednost koja ima visoki specificity i 
# accuracy prilicno visok
# ovo je potrebno izabrati kako zelimo da pobosljamo model

# na slici vidimo da nam je  treshold je 0.242, 
# specificity je 0.756, a sensitivity je 0.764 
# to nam je nb2.coords[23,4] i mozemo to da koristimo te rezultate
# sto smo dobili sa plota
# medjutim mozemo i sami da biramo u zavinosti od zadatka
# ako trazi da specificity bude sto veci ili sensitivity sto veci
# ovde trazimo threshold gde je njihova suma najveca, zato uzimamo 23,4
prob.threshold <- nb2.coords[23,4]
prob.threshold

# sad radimo predikciju sa novim thresholdom
nb2.pred <- ifelse(test = nb2.pred.prob[,1] >= prob.threshold, 
                   yes = "cheap", no = "not_cheap")

# stavili smo nb2.pred.prob[,1] jer nam je pozitivna klasa u prvoj koloni
# u yes se upisuje vrednost nase pozitivne klase, u ovom slucaju to je cheap
# da je bila pozitivna klasa not_cheap onda bi bilo ovako
# nb2.pred <- ifelse(test = nb2.pred.prob[,2] >= prob.threshold, yes = "not_cheap", no = "cheap")

# pretvaramo u faktor da ne bude vektor karaktera
nb2.pred <- as.factor(nb2.pred)

nb2.cm <- table(true = test.set$price_category, predicted = nb2.pred)
nb1.cm
nb2.cm

nb2.eval <- getEvaluationMetrics(nb2.cm)
nb1.eval
nb2.eval

data.frame(rbind(nb1.eval, nb2.eval), row.names = c("one", "two"))

# accuracy i precision su nam gori nego u prethodnom modelu
# recall se znacajno povecao, pa je to zato povuklo i F1 statistiku da 
# se poveca
# dakle nas novi model ima slabiji accuracy i precision
# a bolji recall i f1 statistiku


----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------

EKSPERTNI SISTEMI


package com.sample
 
import com.sample.Krov;
 
rule "Uslov 2"
    when
        k : Krov( prokisnjava.contains("po sredini"), ulegao == true, !potrebniRadovi.contains("zameniti krov") )
    then
		k.getPotrebniRadovi().add("zameniti krov");
		k.setUkupnaCenaRadova(1000 + 10 * k.getKvadratura() );
        update( k );
end

rule "Uslov 3"
    when
        k : Krov ( prokisnjava.contains("po sredini"), brojNedostajucihCrepova > 0, !potrebniRadovi.contains("zameniti crepove") )
    then
        k.getPotrebniRadovi().add("zameniti crepove");
        k.setUkupnaCenaRadova(k.getUkupnaCenaRadova() + 2 * k.getBrojNedostajucihCrepova() );
        update( k );
end

rule "Uslov 4"
    when
        k : Krov ( prokisnjava.contains("po sredini"), brojNedostajucihCrepova == 0, ulegao == false, !potrebniRadovi.contains("pregled krova") )
    then
        k.getPotrebniRadovi().add("pregled krova");
        k.setUkupnaCenaRadova(k.getUkupnaCenaRadova() + 200 );
        update( k );
end

rule "Uslov 5"
    when
        k : Krov ( prokisnjava.contains("oko odzaka"), !potrebniRadovi.contains("olucarski radovi") )
    then
        k.getPotrebniRadovi().add("olucarski radovi");
        k.setUkupnaCenaRadova(k.getUkupnaCenaRadova() + 50 );
        update( k );
end

rule "Uslov 6"
    when
        k : Krov ( prokisnjava.contains("po ivici"), oluciZardjali == true, drvoSaKrosnjom == true, 
					!potrebniRadovi.contains("zameniti oluke"), !potrebniRadovi.contains("skratiti krosnju") )
    then
        k.getPotrebniRadovi().add("zameniti oluke");
        k.getPotrebniRadovi().add("skratiti krosnju");
        k.setUkupnaCenaRadova(k.getUkupnaCenaRadova() + 350 );
        update( k );
end

rule "Uslov 7"
    when
        k : Krov ( prokisnjava.contains("po ivici"), oluciZardjali == false, drvoSaKrosnjom == true, 
					!potrebniRadovi.contains("ocistiti oluke"), !potrebniRadovi.contains("skratiti krosnju") )
    then
        k.getPotrebniRadovi().add("ocistiti oluke");
        k.getPotrebniRadovi().add("skratiti krosnju");
        k.setUkupnaCenaRadova(k.getUkupnaCenaRadova() + 70 );
        update( k );
end

rule "Uslov 8"
    when
        k : Krov ( ( prokisnjava.contains("voda sliva niz zid") || prokisnjava.contains("po ivici") ), oluciZardjali == true, 
        					 !potrebniRadovi.contains("zameniti oluke") )
    then
        k.getPotrebniRadovi().add("zameniti oluke");
        k.setUkupnaCenaRadova(k.getUkupnaCenaRadova() + 300 );
        update( k );
end










----------------------------------------------------------------------------------------------------


NEURONSKE

MOJ ZADATAK


package is.ispit;

import java.util.ArrayList;
import org.neuroph.core.data.DataSet;
import org.neuroph.core.data.DataSetRow;
import org.neuroph.core.events.LearningEvent;
import org.neuroph.core.events.LearningEventListener;
import org.neuroph.eval.classification.ConfusionMatrix;
import org.neuroph.exam.NeurophExam;
import org.neuroph.nnet.MultiLayerPerceptron;
import org.neuroph.nnet.learning.MomentumBackpropagation;
import org.neuroph.util.data.norm.MaxNormalizer;
import org.neuroph.util.data.norm.Normalizer;

/*
    ARI
*/

public class MojZadatak implements NeurophExam, LearningEventListener {

    int inputCount = 8;
    int outputCount = 1;
    DataSet trainSet;
    DataSet testSet;
    double[] learRate = {0.2, 0.3, 0.4};
    ArrayList<Training> trainings = new ArrayList<>();

    /**
     * U ovoj metodi pozivati sve metode koje cete implementirati iz NeurophExam
     * interfejsa
     */
    private void run() {
        DataSet ds = loadDataSet();
        ds = preprocessDataSet(ds);
        DataSet[] trainAndTest = trainTestSplit(ds);
        trainSet = trainAndTest[0];
        testSet = trainAndTest[1];
        MultiLayerPerceptron neuralNet = createNeuralNetwork();
        trainNeuralNetwork(neuralNet, ds);
        saveBestNetwork();
    }

    @Override
    public DataSet loadDataSet() {
        DataSet dataSet = DataSet.createFromFile("diabetes_data.csv", inputCount, outputCount, ",");
        return dataSet;
    }

    @Override
    public DataSet preprocessDataSet(DataSet ds) {
        Normalizer norm = new MaxNormalizer(ds);
        norm.normalize(ds);
        ds.shuffle();
        return ds;
    }

    @Override
    public DataSet[] trainTestSplit(DataSet ds) {
        return ds.split(0.6, 0.4);
    }

    @Override
    public MultiLayerPerceptron createNeuralNetwork() {
        return new MultiLayerPerceptron(inputCount, 20, 16, outputCount);
    }

    @Override
    public MultiLayerPerceptron trainNeuralNetwork(MultiLayerPerceptron mlp, DataSet ds) {

        int numOfIterations = 0;
        int numOfTrainings = 0;

        for (double lr : learRate) {
            MomentumBackpropagation learningRule = (MomentumBackpropagation) mlp.getLearningRule();
            learningRule.addListener(this);

            learningRule.setLearningRate(lr);
            learningRule.setMaxError(0.07);
            learningRule.setMomentum(0.5);
//            learningRule.setMaxIterations(1000);

            mlp.learn(trainSet);

            numOfTrainings++;
            numOfIterations += learningRule.getCurrentIteration();

            evaluate(mlp, testSet);
        }

        System.out.println("Srednja vrednost broja iteracija je: " + (double) numOfIterations / numOfTrainings);

        return mlp;

    }

    @Override
    public void evaluate(MultiLayerPerceptron mlp, DataSet ds) {

        // ova matrica ima 2 classLabela jer ima 1 output
        // matrica ne sme da bude 1x1
        String[] classLabels = new String[]{"c1", "c2"};
        ConfusionMatrix cm = new ConfusionMatrix(classLabels);
        double accuracy = 0;

        for (DataSetRow dataSetRow : ds) {
            mlp.setInput(dataSetRow.getInput());
            mlp.calculate();

            int actual = (int) Math.round(dataSetRow.getDesiredOutput()[0]);
            int predicted = (int) Math.round(mlp.getOutput()[0]);
            
            System.out.println("Actual: " + dataSetRow.getDesiredOutput()[0] 
                            + "\t Predicted: " + mlp.getOutput()[0]);

            cm.incrementElement(actual, predicted);
        }

        accuracy = (double) (cm.getTruePositive(0) + cm.getTrueNegative(0)) / cm.getTotal();

        System.out.println(cm.toString());

        System.out.println("Moj accuracy: " + accuracy);

        Training t = new Training(mlp, accuracy);
        trainings.add(t);
    }

    @Override
    public void saveBestNetwork() {
        Training maxTraining = trainings.get(0);
        for (Training training : trainings) {
            if (training.getAccuracy() > maxTraining.getAccuracy()) {
                maxTraining = training;
            }
        }
        maxTraining.getNeuralNet().save("nn.nnet");
    }

    public static void main(String[] args) {
        new MojZadatak().run();
    }

    @Override
    public void handleLearningEvent(LearningEvent le) {
        MomentumBackpropagation bp = (MomentumBackpropagation) le.getSource();
        System.out.println("Iteration: " + bp.getCurrentIteration()
                + " Total network error: " + bp.getTotalNetworkError());
    }

    private int getMaxIndex(double[] output) {
        int max = 0;
        for (int i = 1; i < output.length; i++) {
            if (output[max] < output[i]) {
                max = i;
            }
        }
        return max;
    }
 
/*
    ARI
*/

}




TRAINING


/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package is.ispit;

import org.neuroph.core.NeuralNetwork;

/**
 *
 * @author Ari
 */
public class Training {
    
    private NeuralNetwork neuralNet;
    private double accuracy;

    public Training(NeuralNetwork neuralNet, double accuracy) {
        this.neuralNet = neuralNet;
        this.accuracy = accuracy;
    }

    public double getAccuracy() {
        return accuracy;
    }

    public void setAccuracy(double accuracy) {
        this.accuracy = accuracy;
    }

    public NeuralNetwork getNeuralNet() {
        return neuralNet;
    }

    public void setNeuralNet(NeuralNetwork neuralNet) {
        this.neuralNet = neuralNet;
    }
    
    
    
}




